{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759e1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data  as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "from torchvision import utils \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import copy\n",
    "from random import *\n",
    "import math\n",
    "\n",
    "import h5py\n",
    "import cmath\n",
    "import time\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f84696",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 2 # complex number\n",
    "m = 16 # number of vertical antennas in BS \n",
    "n = 16 # number of horizental antennas in BS\n",
    "N_BS = m*n # total number of antennas in BS\n",
    "N_ms = 1\n",
    "cr = 1/2 # compressive ratio, (pilot length)/(N_BS)\n",
    "mtx_v = N_BS # pilot matrix's shape is mtx_v x mtx_h\n",
    "mtx_h = int(N_BS*cr)\n",
    "output_dim = int(N_BS*cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "962a2759",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = [0, 5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01910e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR = [0, 10, 20]\n",
    "# data loading\n",
    "train = 'H_train.mat'\n",
    "val = 'H_val.mat'\n",
    "test = 'H_test.mat'\n",
    "\n",
    "mat = scipy.io.loadmat(train)\n",
    "x_train = mat['H_train']\n",
    "x_train = x_train.astype('float32')\n",
    "\n",
    "mat = scipy.io.loadmat(val)\n",
    "x_val = mat['H_val']\n",
    "x_val = x_val.astype('float32')\n",
    "\n",
    "mat = scipy.io.loadmat(test)\n",
    "x_test = mat['H_test']\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d4e755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl=data.DataLoader(x_train, batch_size=128, shuffle=True)\n",
    "val_dl=data.DataLoader(x_val, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10623a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class channel_estimation(nn.Module):\n",
    "    def __init__(self, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.output_dim=output_dim\n",
    "        self.SN=nn.Linear(N_BS, output_dim, bias=False) \n",
    "        self.decode=nn.Linear(output_dim, N_BS, bias=False)\n",
    "        \n",
    "        self.f1=nn.Sequential(\n",
    "            nn.Conv2d(2, 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.LeakyReLU()\n",
    "            )\n",
    "        self.f2=nn.Sequential(\n",
    "            nn.Conv2d(2, 4, 3, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.LeakyReLU()\n",
    "            )\n",
    "        self.f3=nn.Sequential(\n",
    "            nn.Conv2d(4, 8, 3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU()\n",
    "            )\n",
    "        self.f4=nn.Sequential(\n",
    "            nn.Conv2d(8, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU()\n",
    "            )\n",
    "        self.f5=nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU()\n",
    "            )\n",
    "        self.f6=nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU()\n",
    "            )\n",
    "        self.f7=nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU()\n",
    "            )\n",
    "        self.f8=nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU()\n",
    "            )\n",
    "        self.f9=nn.Sequential(\n",
    "            nn.Conv2d(256, 2, 3, padding=1),\n",
    "            nn.BatchNorm2d(2)\n",
    "            )\n",
    "        self.shortcut=nn.Sequential()\n",
    "        self.LReLU=nn.LeakyReLU()\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    def forward(self, x):\n",
    "        y=self.SN(x)\n",
    "#         print('signal_shape')\n",
    "#         print(y.shape)\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            sig_power=torch.mean(y**2, axis=1, keepdims=True)\n",
    "    #         print(sig_power.shape)\n",
    "            noise_var=torch.sqrt(sig_power/(10**(snr/10))).to(device)\n",
    "            noise =torch.normal(0,1,size=y.shape).to(device)\n",
    "            noise=noise_var*noise\n",
    "    #         print('noise')\n",
    "    #         print(noise.shape)\n",
    "    #         y_t=torch.sum(y**2, axis=1)\n",
    "    #         y_t=torch.sum(y_t, axis=1)\n",
    "    #         n_t=torch.sum(noise**2, axis=1)\n",
    "    #         n_t=torch.sum(n_t, axis=1)\n",
    "    #         snr_t=torch.mean(y_t/n_t)\n",
    "    #         print((y_t/n_t).shape)\n",
    "    #         print(10* math.log10(snr_t))\n",
    "        y=y+noise\n",
    "        x=self.decode(y)\n",
    "        x=x.reshape(x.shape[0], 2, m,n)\n",
    "        t=x # shortcut\n",
    "        x=self.f1(x)\n",
    "        x=self.f2(x)\n",
    "        x=self.f3(x)\n",
    "        x=self.f4(x)\n",
    "        x=self.f5(x)\n",
    "        x=self.f6(x)\n",
    "        x=self.f7(x)\n",
    "        x=self.f8(x)\n",
    "        x=self.f9(x)+self.shortcut(t)\n",
    "        x=self.LReLU(x)\n",
    "        x=x.reshape(x.shape[0],2,N_BS)\n",
    "        return x\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0f3518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "snr=0\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=channel_estimation().to(device)\n",
    "x=torch.randn(200, 2,256).to(device)\n",
    "output=model(x)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9680aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_batch(output, target): \n",
    "    # NMSE metric\n",
    "    x_re=target[:,0,:]\n",
    "    x_im=target[:,1,:]\n",
    "    x_t=x_re+1j*x_im\n",
    "    \n",
    "    x_h_re=output[:,0,:]\n",
    "    x_h_im=output[:,1,:]\n",
    "    x_h_t=x_h_re+1j*x_h_im\n",
    "    \n",
    "    power=torch.sum(abs(x_t)**2, axis=1)\n",
    "    mse=torch.sum(abs(x_t-x_h_t)**2, axis=1)    \n",
    "    result=10*math.log10(torch.mean(mse/power))\n",
    "    return result\n",
    "\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss=loss_func(output, target)\n",
    "    metric_b=metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss=0.0\n",
    "    running_metric=0.0\n",
    "    len_data=len(dataset_dl.dataset)\n",
    "    \n",
    "    for xb in dataset_dl:\n",
    "        xb=xb.float()\n",
    "        xb=xb.to(device)\n",
    "        output=model(xb)   \n",
    "        loss_b, metric_b=loss_batch(loss_func, output, xb, opt)\n",
    "        running_loss+=loss_b\n",
    "\n",
    "        if metric_b is not None:\n",
    "            running_metric+=metric_b\n",
    "\n",
    "        if sanity_check is True:\n",
    "            break\n",
    "    loss=running_loss/(len_data/128)\n",
    "    metric=running_metric/(len_data/128)\n",
    "\n",
    "    return loss, metric\n",
    "\n",
    "def train_val(model, params):\n",
    "    num_epochs=params['num_epochs']\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "\n",
    "    loss_history={'train': [], 'val': []}\n",
    "    metric_history={'train': [], 'val': []}\n",
    "\n",
    "    best_loss=float('inf')\n",
    "    start_time=time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs-1))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric=loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric=loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "            loss_history['val'].append(val_loss)\n",
    "            metric_history['val'].append(val_metric)\n",
    "\n",
    "            if val_loss<best_loss:\n",
    "                best_loss=val_loss\n",
    "                print('Get best val_loss')\n",
    "                torch.save(model.state_dict(), f'.\\\\models_torch\\\\{cr}_{snr}_inverse_bestloss.pt')\n",
    "                torch.save(model,f'.\\\\models_torch\\\\params\\\\{cr}_{snr}_inverse_bestloss_model.pt')\n",
    "            \n",
    "\n",
    "            print('SNR is %d dB, %d th iteration, train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(snr, iters,  train_loss, val_loss, val_metric, (time.time()-start_time/60)))\n",
    "            print('-'*10)\n",
    "\n",
    "    torch.save(model.state_dict(), f'.\\\\models_torch\\\\{cr}_{snr}_inverse.pt')\n",
    "    torch.save(model,f'.\\\\models_torch\\\\params\\\\{cr}_{snr}_inverse_model.pt')\n",
    "    print(f'SNR: {snr}, the {iters} th model is saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20282588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.333723, val loss: 0.306319, accuracy: -2.09, time: 1612601127.5321 min\n",
      "----------\n",
      "Epoch 1/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.286622, val loss: 0.278870, accuracy: -2.49, time: 1612601230.1004 min\n",
      "----------\n",
      "Epoch 2/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.256482, val loss: 0.251062, accuracy: -2.93, time: 1612601332.7651 min\n",
      "----------\n",
      "Epoch 3/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.229899, val loss: 0.223996, accuracy: -3.42, time: 1612601435.2900 min\n",
      "----------\n",
      "Epoch 4/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.207296, val loss: 0.206574, accuracy: -3.74, time: 1612601537.8037 min\n",
      "----------\n",
      "Epoch 5/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.188453, val loss: 0.185364, accuracy: -4.22, time: 1612601640.3594 min\n",
      "----------\n",
      "Epoch 6/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.173234, val loss: 0.174763, accuracy: -4.46, time: 1612601742.8325 min\n",
      "----------\n",
      "Epoch 7/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.160934, val loss: 0.159777, accuracy: -4.84, time: 1612601845.2497 min\n",
      "----------\n",
      "Epoch 8/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.151395, val loss: 0.154649, accuracy: -4.95, time: 1612601947.6748 min\n",
      "----------\n",
      "Epoch 9/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.144220, val loss: 0.149191, accuracy: -5.12, time: 1612602050.1746 min\n",
      "----------\n",
      "Epoch 10/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.138766, val loss: 0.142707, accuracy: -5.30, time: 1612602152.6367 min\n",
      "----------\n",
      "Epoch 11/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.134679, val loss: 0.137939, accuracy: -5.46, time: 1612602255.1576 min\n",
      "----------\n",
      "Epoch 12/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.131595, val loss: 0.135834, accuracy: -5.53, time: 1612602357.6812 min\n",
      "----------\n",
      "Epoch 13/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.129203, val loss: 0.134049, accuracy: -5.57, time: 1612602460.1916 min\n",
      "----------\n",
      "Epoch 14/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.127377, val loss: 0.137103, accuracy: -5.45, time: 1612602562.7081 min\n",
      "----------\n",
      "Epoch 15/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.125873, val loss: 0.141742, accuracy: -5.28, time: 1612602665.1976 min\n",
      "----------\n",
      "Epoch 16/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.124615, val loss: 0.132405, accuracy: -5.63, time: 1612602767.7152 min\n",
      "----------\n",
      "Epoch 17/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.123748, val loss: 0.130352, accuracy: -5.68, time: 1612602870.3707 min\n",
      "----------\n",
      "Epoch 18/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.122799, val loss: 0.131463, accuracy: -5.66, time: 1612602972.9542 min\n",
      "----------\n",
      "Epoch 19/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.122328, val loss: 0.134574, accuracy: -5.55, time: 1612603075.5469 min\n",
      "----------\n",
      "Epoch 20/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.121548, val loss: 0.128663, accuracy: -5.74, time: 1612603178.0942 min\n",
      "----------\n",
      "Epoch 21/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.121174, val loss: 0.132175, accuracy: -5.61, time: 1612603280.6560 min\n",
      "----------\n",
      "Epoch 22/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.120728, val loss: 0.131435, accuracy: -5.65, time: 1612603383.3418 min\n",
      "----------\n",
      "Epoch 23/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.120452, val loss: 0.127417, accuracy: -5.80, time: 1612603485.8821 min\n",
      "----------\n",
      "Epoch 24/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.120018, val loss: 0.135468, accuracy: -5.48, time: 1612603588.4101 min\n",
      "----------\n",
      "Epoch 25/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.119811, val loss: 0.129837, accuracy: -5.69, time: 1612603690.8954 min\n",
      "----------\n",
      "Epoch 26/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.119414, val loss: 0.128050, accuracy: -5.77, time: 1612603793.3893 min\n",
      "----------\n",
      "Epoch 27/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.119269, val loss: 0.129356, accuracy: -5.71, time: 1612603895.9008 min\n",
      "----------\n",
      "Epoch 28/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.119062, val loss: 0.134740, accuracy: -5.51, time: 1612603998.3822 min\n",
      "----------\n",
      "Epoch 29/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.118876, val loss: 0.129597, accuracy: -5.72, time: 1612604100.8900 min\n",
      "----------\n",
      "Epoch 30/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.118640, val loss: 0.126609, accuracy: -5.82, time: 1612604203.3851 min\n",
      "----------\n",
      "Epoch 31/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.118490, val loss: 0.128779, accuracy: -5.73, time: 1612604305.8807 min\n",
      "----------\n",
      "Epoch 32/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.118294, val loss: 0.127225, accuracy: -5.79, time: 1612604408.4141 min\n",
      "----------\n",
      "Epoch 33/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.118107, val loss: 0.148887, accuracy: -5.07, time: 1612604510.9341 min\n",
      "----------\n",
      "Epoch 34/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.118000, val loss: 0.127334, accuracy: -5.80, time: 1612604613.4920 min\n",
      "----------\n",
      "Epoch 35/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117860, val loss: 0.132680, accuracy: -5.57, time: 1612604716.0054 min\n",
      "----------\n",
      "Epoch 36/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117721, val loss: 0.126407, accuracy: -5.83, time: 1612604818.5612 min\n",
      "----------\n",
      "Epoch 37/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117628, val loss: 0.128738, accuracy: -5.75, time: 1612604921.0946 min\n",
      "----------\n",
      "Epoch 38/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117413, val loss: 0.125651, accuracy: -5.86, time: 1612605023.7707 min\n",
      "----------\n",
      "Epoch 39/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117353, val loss: 0.126718, accuracy: -5.82, time: 1612605126.2918 min\n",
      "----------\n",
      "Epoch 40/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117369, val loss: 0.126157, accuracy: -5.84, time: 1612605228.7920 min\n",
      "----------\n",
      "Epoch 41/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117155, val loss: 0.128554, accuracy: -5.77, time: 1612605331.3236 min\n",
      "----------\n",
      "Epoch 42/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117044, val loss: 0.130252, accuracy: -5.70, time: 1612605433.8871 min\n",
      "----------\n",
      "Epoch 43/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.117026, val loss: 0.126782, accuracy: -5.82, time: 1612605536.4362 min\n",
      "----------\n",
      "Epoch 44/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116964, val loss: 0.126242, accuracy: -5.83, time: 1612605638.9218 min\n",
      "----------\n",
      "Epoch 45/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116877, val loss: 0.125890, accuracy: -5.86, time: 1612605741.3906 min\n",
      "----------\n",
      "Epoch 46/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116768, val loss: 0.125500, accuracy: -5.87, time: 1612605843.8565 min\n",
      "----------\n",
      "Epoch 47/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116729, val loss: 0.127359, accuracy: -5.81, time: 1612605946.3663 min\n",
      "----------\n",
      "Epoch 48/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116606, val loss: 0.125196, accuracy: -5.88, time: 1612606048.8817 min\n",
      "----------\n",
      "Epoch 49/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116551, val loss: 0.127536, accuracy: -5.78, time: 1612606151.4090 min\n",
      "----------\n",
      "Epoch 50/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116431, val loss: 0.126304, accuracy: -5.84, time: 1612606253.8919 min\n",
      "----------\n",
      "Epoch 51/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116454, val loss: 0.127015, accuracy: -5.81, time: 1612606356.3683 min\n",
      "----------\n",
      "Epoch 52/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116371, val loss: 0.127239, accuracy: -5.81, time: 1612606458.8856 min\n",
      "----------\n",
      "Epoch 53/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116277, val loss: 0.125627, accuracy: -5.86, time: 1612606561.3732 min\n",
      "----------\n",
      "Epoch 54/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116199, val loss: 0.127500, accuracy: -5.80, time: 1612606663.8487 min\n",
      "----------\n",
      "Epoch 55/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116151, val loss: 0.125493, accuracy: -5.87, time: 1612606766.3597 min\n",
      "----------\n",
      "Epoch 56/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116075, val loss: 0.133590, accuracy: -5.59, time: 1612606868.8717 min\n",
      "----------\n",
      "Epoch 57/299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116062, val loss: 0.125143, accuracy: -5.88, time: 1612606971.3790 min\n",
      "----------\n",
      "Epoch 58/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.116034, val loss: 0.128537, accuracy: -5.75, time: 1612607073.9691 min\n",
      "----------\n",
      "Epoch 59/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115879, val loss: 0.124695, accuracy: -5.89, time: 1612607176.5533 min\n",
      "----------\n",
      "Epoch 60/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115848, val loss: 0.125035, accuracy: -5.88, time: 1612607279.1053 min\n",
      "----------\n",
      "Epoch 61/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115784, val loss: 0.126196, accuracy: -5.85, time: 1612607381.6874 min\n",
      "----------\n",
      "Epoch 62/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115693, val loss: 0.125714, accuracy: -5.86, time: 1612607484.2949 min\n",
      "----------\n",
      "Epoch 63/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115722, val loss: 0.125014, accuracy: -5.87, time: 1612607586.8467 min\n",
      "----------\n",
      "Epoch 64/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115650, val loss: 0.125216, accuracy: -5.87, time: 1612607689.3758 min\n",
      "----------\n",
      "Epoch 65/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115605, val loss: 0.125328, accuracy: -5.86, time: 1612607791.9117 min\n",
      "----------\n",
      "Epoch 66/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115480, val loss: 0.126085, accuracy: -5.84, time: 1612607894.6315 min\n",
      "----------\n",
      "Epoch 67/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115448, val loss: 0.125645, accuracy: -5.86, time: 1612607997.2975 min\n",
      "----------\n",
      "Epoch 68/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115451, val loss: 0.125909, accuracy: -5.84, time: 1612608099.8624 min\n",
      "----------\n",
      "Epoch 69/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115424, val loss: 0.125004, accuracy: -5.88, time: 1612608202.3721 min\n",
      "----------\n",
      "Epoch 70/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115480, val loss: 0.130109, accuracy: -5.72, time: 1612608304.9020 min\n",
      "----------\n",
      "Epoch 71/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115412, val loss: 0.128173, accuracy: -5.76, time: 1612608407.4440 min\n",
      "----------\n",
      "Epoch 72/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115271, val loss: 0.126511, accuracy: -5.84, time: 1612608509.9774 min\n",
      "----------\n",
      "Epoch 73/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115267, val loss: 0.125564, accuracy: -5.85, time: 1612608612.5117 min\n",
      "----------\n",
      "Epoch 74/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115250, val loss: 0.126391, accuracy: -5.82, time: 1612608715.0343 min\n",
      "----------\n",
      "Epoch 75/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115270, val loss: 0.124827, accuracy: -5.89, time: 1612608817.5252 min\n",
      "----------\n",
      "Epoch 76/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115080, val loss: 0.125364, accuracy: -5.88, time: 1612608920.0116 min\n",
      "----------\n",
      "Epoch 77/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115128, val loss: 0.124564, accuracy: -5.90, time: 1612609022.5745 min\n",
      "----------\n",
      "Epoch 78/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115047, val loss: 0.129057, accuracy: -5.75, time: 1612609125.0594 min\n",
      "----------\n",
      "Epoch 79/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114970, val loss: 0.125246, accuracy: -5.88, time: 1612609227.5806 min\n",
      "----------\n",
      "Epoch 80/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115017, val loss: 0.129241, accuracy: -5.75, time: 1612609330.0722 min\n",
      "----------\n",
      "Epoch 81/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115020, val loss: 0.125996, accuracy: -5.86, time: 1612609432.5733 min\n",
      "----------\n",
      "Epoch 82/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.115054, val loss: 0.124880, accuracy: -5.89, time: 1612609535.2650 min\n",
      "----------\n",
      "Epoch 83/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114962, val loss: 0.124447, accuracy: -5.90, time: 1612609637.7928 min\n",
      "----------\n",
      "Epoch 84/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114898, val loss: 0.129977, accuracy: -5.74, time: 1612609740.3145 min\n",
      "----------\n",
      "Epoch 85/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114839, val loss: 0.125575, accuracy: -5.87, time: 1612609842.7985 min\n",
      "----------\n",
      "Epoch 86/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114814, val loss: 0.127195, accuracy: -5.82, time: 1612609945.3148 min\n",
      "----------\n",
      "Epoch 87/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114854, val loss: 0.126779, accuracy: -5.82, time: 1612610047.8725 min\n",
      "----------\n",
      "Epoch 88/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114748, val loss: 0.126960, accuracy: -5.82, time: 1612610150.3476 min\n",
      "----------\n",
      "Epoch 89/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114746, val loss: 0.127647, accuracy: -5.80, time: 1612610252.8380 min\n",
      "----------\n",
      "Epoch 90/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114684, val loss: 0.126079, accuracy: -5.84, time: 1612610355.2929 min\n",
      "----------\n",
      "Epoch 91/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114607, val loss: 0.127108, accuracy: -5.79, time: 1612610457.8766 min\n",
      "----------\n",
      "Epoch 92/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114644, val loss: 0.125008, accuracy: -5.88, time: 1612610560.3322 min\n",
      "----------\n",
      "Epoch 93/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114646, val loss: 0.126809, accuracy: -5.82, time: 1612610662.8524 min\n",
      "----------\n",
      "Epoch 94/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114597, val loss: 0.124568, accuracy: -5.90, time: 1612610765.9325 min\n",
      "----------\n",
      "Epoch 95/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114554, val loss: 0.127514, accuracy: -5.78, time: 1612610868.4269 min\n",
      "----------\n",
      "Epoch 96/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114522, val loss: 0.124724, accuracy: -5.90, time: 1612610970.9709 min\n",
      "----------\n",
      "Epoch 97/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114511, val loss: 0.131104, accuracy: -5.65, time: 1612611073.4410 min\n",
      "----------\n",
      "Epoch 98/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114463, val loss: 0.126365, accuracy: -5.84, time: 1612611175.9586 min\n",
      "----------\n",
      "Epoch 99/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114496, val loss: 0.124941, accuracy: -5.90, time: 1612611278.3808 min\n",
      "----------\n",
      "Epoch 100/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114400, val loss: 0.130574, accuracy: -5.66, time: 1612611380.8650 min\n",
      "----------\n",
      "Epoch 101/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114433, val loss: 0.124890, accuracy: -5.90, time: 1612611483.3265 min\n",
      "----------\n",
      "Epoch 102/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114309, val loss: 0.126737, accuracy: -5.81, time: 1612611585.8481 min\n",
      "----------\n",
      "Epoch 103/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114238, val loss: 0.135722, accuracy: -5.51, time: 1612611688.3500 min\n",
      "----------\n",
      "Epoch 104/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114319, val loss: 0.124718, accuracy: -5.90, time: 1612611790.8681 min\n",
      "----------\n",
      "Epoch 105/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114248, val loss: 0.124524, accuracy: -5.90, time: 1612611893.4339 min\n",
      "----------\n",
      "Epoch 106/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114167, val loss: 0.124760, accuracy: -5.89, time: 1612611995.9571 min\n",
      "----------\n",
      "Epoch 107/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114249, val loss: 0.125568, accuracy: -5.87, time: 1612612098.4594 min\n",
      "----------\n",
      "Epoch 108/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114244, val loss: 0.125676, accuracy: -5.85, time: 1612612200.9874 min\n",
      "----------\n",
      "Epoch 109/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114236, val loss: 0.129241, accuracy: -5.70, time: 1612612303.5400 min\n",
      "----------\n",
      "Epoch 110/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114224, val loss: 0.125264, accuracy: -5.88, time: 1612612406.0231 min\n",
      "----------\n",
      "Epoch 111/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114105, val loss: 0.128229, accuracy: -5.77, time: 1612612508.5305 min\n",
      "----------\n",
      "Epoch 112/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114191, val loss: 0.124278, accuracy: -5.92, time: 1612612611.0401 min\n",
      "----------\n",
      "Epoch 113/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114104, val loss: 0.125615, accuracy: -5.85, time: 1612612713.5553 min\n",
      "----------\n",
      "Epoch 114/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114088, val loss: 0.126811, accuracy: -5.84, time: 1612612816.0430 min\n",
      "----------\n",
      "Epoch 115/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114113, val loss: 0.124531, accuracy: -5.91, time: 1612612918.5866 min\n",
      "----------\n",
      "Epoch 116/299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR is 0 dB, 0 th iteration, train loss: 0.113988, val loss: 0.126169, accuracy: -5.84, time: 1612613021.0440 min\n",
      "----------\n",
      "Epoch 117/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.114076, val loss: 0.128214, accuracy: -5.78, time: 1612613123.5548 min\n",
      "----------\n",
      "Epoch 118/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113899, val loss: 0.125446, accuracy: -5.87, time: 1612613226.1426 min\n",
      "----------\n",
      "Epoch 119/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113911, val loss: 0.125837, accuracy: -5.84, time: 1612613328.6121 min\n",
      "----------\n",
      "Epoch 120/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113937, val loss: 0.124593, accuracy: -5.90, time: 1612613431.0701 min\n",
      "----------\n",
      "Epoch 121/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113961, val loss: 0.125371, accuracy: -5.88, time: 1612613533.5893 min\n",
      "----------\n",
      "Epoch 122/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113929, val loss: 0.125289, accuracy: -5.87, time: 1612613636.0711 min\n",
      "----------\n",
      "Epoch 123/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113968, val loss: 0.125991, accuracy: -5.84, time: 1612613738.5861 min\n",
      "----------\n",
      "Epoch 124/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113935, val loss: 0.125205, accuracy: -5.89, time: 1612613841.0450 min\n",
      "----------\n",
      "Epoch 125/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113797, val loss: 0.125097, accuracy: -5.87, time: 1612613943.5758 min\n",
      "----------\n",
      "Epoch 126/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113945, val loss: 0.126300, accuracy: -5.84, time: 1612614046.0718 min\n",
      "----------\n",
      "Epoch 127/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113757, val loss: 0.124869, accuracy: -5.88, time: 1612614148.6272 min\n",
      "----------\n",
      "Epoch 128/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113866, val loss: 0.124836, accuracy: -5.90, time: 1612614251.1815 min\n",
      "----------\n",
      "Epoch 129/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113797, val loss: 0.124747, accuracy: -5.90, time: 1612614353.6829 min\n",
      "----------\n",
      "Epoch 130/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113779, val loss: 0.127383, accuracy: -5.82, time: 1612614456.2553 min\n",
      "----------\n",
      "Epoch 131/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113818, val loss: 0.125330, accuracy: -5.87, time: 1612614558.7783 min\n",
      "----------\n",
      "Epoch 132/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113678, val loss: 0.126037, accuracy: -5.83, time: 1612614661.3043 min\n",
      "----------\n",
      "Epoch 133/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113716, val loss: 0.128175, accuracy: -5.78, time: 1612614763.7950 min\n",
      "----------\n",
      "Epoch 134/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113720, val loss: 0.125155, accuracy: -5.89, time: 1612614866.2656 min\n",
      "----------\n",
      "Epoch 135/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113711, val loss: 0.124898, accuracy: -5.90, time: 1612614968.7657 min\n",
      "----------\n",
      "Epoch 136/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113668, val loss: 0.126880, accuracy: -5.82, time: 1612615071.2463 min\n",
      "----------\n",
      "Epoch 137/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113719, val loss: 0.125936, accuracy: -5.86, time: 1612615173.7674 min\n",
      "----------\n",
      "Epoch 138/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113595, val loss: 0.124892, accuracy: -5.89, time: 1612615276.3441 min\n",
      "----------\n",
      "Epoch 139/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113580, val loss: 0.128989, accuracy: -5.75, time: 1612615378.9104 min\n",
      "----------\n",
      "Epoch 140/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113666, val loss: 0.126421, accuracy: -5.84, time: 1612615481.3997 min\n",
      "----------\n",
      "Epoch 141/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113614, val loss: 0.129810, accuracy: -5.70, time: 1612615584.0231 min\n",
      "----------\n",
      "Epoch 142/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113541, val loss: 0.125020, accuracy: -5.89, time: 1612615686.6233 min\n",
      "----------\n",
      "Epoch 143/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113549, val loss: 0.124465, accuracy: -5.91, time: 1612615789.1886 min\n",
      "----------\n",
      "Epoch 144/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113442, val loss: 0.124570, accuracy: -5.91, time: 1612615891.7464 min\n",
      "----------\n",
      "Epoch 145/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113443, val loss: 0.127538, accuracy: -5.81, time: 1612615994.4220 min\n",
      "----------\n",
      "Epoch 146/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113446, val loss: 0.125641, accuracy: -5.87, time: 1612616097.0775 min\n",
      "----------\n",
      "Epoch 147/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113455, val loss: 0.124199, accuracy: -5.91, time: 1612616199.5996 min\n",
      "----------\n",
      "Epoch 148/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113385, val loss: 0.126995, accuracy: -5.83, time: 1612616302.1752 min\n",
      "----------\n",
      "Epoch 149/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113456, val loss: 0.125132, accuracy: -5.88, time: 1612616404.7472 min\n",
      "----------\n",
      "Epoch 150/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113446, val loss: 0.125143, accuracy: -5.87, time: 1612616507.2833 min\n",
      "----------\n",
      "Epoch 151/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113418, val loss: 0.124833, accuracy: -5.90, time: 1612616609.8783 min\n",
      "----------\n",
      "Epoch 152/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113375, val loss: 0.124591, accuracy: -5.90, time: 1612616712.4573 min\n",
      "----------\n",
      "Epoch 153/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113428, val loss: 0.124709, accuracy: -5.91, time: 1612616815.1636 min\n",
      "----------\n",
      "Epoch 154/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113364, val loss: 0.124603, accuracy: -5.90, time: 1612616917.7127 min\n",
      "----------\n",
      "Epoch 155/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113319, val loss: 0.125563, accuracy: -5.85, time: 1612617020.2410 min\n",
      "----------\n",
      "Epoch 156/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113371, val loss: 0.125991, accuracy: -5.86, time: 1612617122.8317 min\n",
      "----------\n",
      "Epoch 157/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113258, val loss: 0.124237, accuracy: -5.91, time: 1612617225.3985 min\n",
      "----------\n",
      "Epoch 158/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113310, val loss: 0.124355, accuracy: -5.91, time: 1612617327.9641 min\n",
      "----------\n",
      "Epoch 159/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113315, val loss: 0.124594, accuracy: -5.90, time: 1612617430.4803 min\n",
      "----------\n",
      "Epoch 160/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113244, val loss: 0.123914, accuracy: -5.93, time: 1612617533.0379 min\n",
      "----------\n",
      "Epoch 161/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113284, val loss: 0.125571, accuracy: -5.88, time: 1612617635.5486 min\n",
      "----------\n",
      "Epoch 162/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113278, val loss: 0.132759, accuracy: -5.63, time: 1612617738.1154 min\n",
      "----------\n",
      "Epoch 163/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113219, val loss: 0.129371, accuracy: -5.72, time: 1612617840.6579 min\n",
      "----------\n",
      "Epoch 164/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113203, val loss: 0.129152, accuracy: -5.72, time: 1612617943.1856 min\n",
      "----------\n",
      "Epoch 165/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113242, val loss: 0.124595, accuracy: -5.89, time: 1612618045.7227 min\n",
      "----------\n",
      "Epoch 166/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113151, val loss: 0.127104, accuracy: -5.82, time: 1612618148.3371 min\n",
      "----------\n",
      "Epoch 167/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113151, val loss: 0.127234, accuracy: -5.79, time: 1612618250.9513 min\n",
      "----------\n",
      "Epoch 168/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113207, val loss: 0.125358, accuracy: -5.87, time: 1612618353.6162 min\n",
      "----------\n",
      "Epoch 169/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113155, val loss: 0.126276, accuracy: -5.85, time: 1612618456.1740 min\n",
      "----------\n",
      "Epoch 170/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113095, val loss: 0.125975, accuracy: -5.84, time: 1612618558.7320 min\n",
      "----------\n",
      "Epoch 171/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113090, val loss: 0.133587, accuracy: -5.61, time: 1612618661.4259 min\n",
      "----------\n",
      "Epoch 172/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113191, val loss: 0.124657, accuracy: -5.90, time: 1612618764.0033 min\n",
      "----------\n",
      "Epoch 173/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113126, val loss: 0.125994, accuracy: -5.86, time: 1612618866.6322 min\n",
      "----------\n",
      "Epoch 174/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113003, val loss: 0.125637, accuracy: -5.87, time: 1612618969.1712 min\n",
      "----------\n",
      "Epoch 175/299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR is 0 dB, 0 th iteration, train loss: 0.113084, val loss: 0.126041, accuracy: -5.86, time: 1612619071.7247 min\n",
      "----------\n",
      "Epoch 176/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113135, val loss: 0.126530, accuracy: -5.81, time: 1612619174.3123 min\n",
      "----------\n",
      "Epoch 177/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113075, val loss: 0.125360, accuracy: -5.89, time: 1612619276.9723 min\n",
      "----------\n",
      "Epoch 178/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113042, val loss: 0.125254, accuracy: -5.88, time: 1612619379.5667 min\n",
      "----------\n",
      "Epoch 179/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112963, val loss: 0.129582, accuracy: -5.74, time: 1612619482.1472 min\n",
      "----------\n",
      "Epoch 180/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.113087, val loss: 0.125778, accuracy: -5.84, time: 1612619584.7838 min\n",
      "----------\n",
      "Epoch 181/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112967, val loss: 0.126910, accuracy: -5.83, time: 1612619687.3098 min\n",
      "----------\n",
      "Epoch 182/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112909, val loss: 0.124199, accuracy: -5.92, time: 1612619789.8220 min\n",
      "----------\n",
      "Epoch 183/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112981, val loss: 0.123981, accuracy: -5.93, time: 1612619892.3515 min\n",
      "----------\n",
      "Epoch 184/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112900, val loss: 0.124340, accuracy: -5.90, time: 1612619994.9085 min\n",
      "----------\n",
      "Epoch 185/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112958, val loss: 0.127844, accuracy: -5.80, time: 1612620097.4411 min\n",
      "----------\n",
      "Epoch 186/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112906, val loss: 0.125346, accuracy: -5.88, time: 1612620199.9902 min\n",
      "----------\n",
      "Epoch 187/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112848, val loss: 0.124775, accuracy: -5.90, time: 1612620302.5614 min\n",
      "----------\n",
      "Epoch 188/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112909, val loss: 0.145500, accuracy: -5.18, time: 1612620405.1311 min\n",
      "----------\n",
      "Epoch 189/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112966, val loss: 0.126028, accuracy: -5.85, time: 1612620507.7016 min\n",
      "----------\n",
      "Epoch 190/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112873, val loss: 0.125067, accuracy: -5.89, time: 1612620610.2417 min\n",
      "----------\n",
      "Epoch 191/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112831, val loss: 0.124823, accuracy: -5.90, time: 1612620712.7911 min\n",
      "----------\n",
      "Epoch 192/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112942, val loss: 0.127297, accuracy: -5.81, time: 1612620815.4604 min\n",
      "----------\n",
      "Epoch 193/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112834, val loss: 0.124085, accuracy: -5.92, time: 1612620917.9974 min\n",
      "----------\n",
      "Epoch 194/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112849, val loss: 0.124482, accuracy: -5.91, time: 1612621020.5938 min\n",
      "----------\n",
      "Epoch 195/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112783, val loss: 0.125516, accuracy: -5.88, time: 1612621123.1625 min\n",
      "----------\n",
      "Epoch 196/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112903, val loss: 0.124290, accuracy: -5.91, time: 1612621225.8080 min\n",
      "----------\n",
      "Epoch 197/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112822, val loss: 0.125301, accuracy: -5.89, time: 1612621328.3418 min\n",
      "----------\n",
      "Epoch 198/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112825, val loss: 0.124525, accuracy: -5.91, time: 1612621430.9026 min\n",
      "----------\n",
      "Epoch 199/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112776, val loss: 0.124856, accuracy: -5.89, time: 1612621533.4732 min\n",
      "----------\n",
      "Epoch 200/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112770, val loss: 0.124253, accuracy: -5.92, time: 1612621636.0108 min\n",
      "----------\n",
      "Epoch 201/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112790, val loss: 0.124119, accuracy: -5.92, time: 1612621738.6241 min\n",
      "----------\n",
      "Epoch 202/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112818, val loss: 0.126276, accuracy: -5.83, time: 1612621841.1552 min\n",
      "----------\n",
      "Epoch 203/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112675, val loss: 0.124092, accuracy: -5.92, time: 1612621943.6491 min\n",
      "----------\n",
      "Epoch 204/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112665, val loss: 0.127596, accuracy: -5.80, time: 1612622046.1670 min\n",
      "----------\n",
      "Epoch 205/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112681, val loss: 0.124614, accuracy: -5.90, time: 1612622148.6567 min\n",
      "----------\n",
      "Epoch 206/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112736, val loss: 0.126034, accuracy: -5.86, time: 1612622251.3246 min\n",
      "----------\n",
      "Epoch 207/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112657, val loss: 0.124604, accuracy: -5.92, time: 1612622353.8561 min\n",
      "----------\n",
      "Epoch 208/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112705, val loss: 0.127407, accuracy: -5.81, time: 1612622456.4758 min\n",
      "----------\n",
      "Epoch 209/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112749, val loss: 0.126359, accuracy: -5.83, time: 1612622559.0681 min\n",
      "----------\n",
      "Epoch 210/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112767, val loss: 0.125479, accuracy: -5.88, time: 1612622661.6377 min\n",
      "----------\n",
      "Epoch 211/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112679, val loss: 0.130005, accuracy: -5.72, time: 1612622764.2543 min\n",
      "----------\n",
      "Epoch 212/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112671, val loss: 0.124581, accuracy: -5.90, time: 1612622866.9868 min\n",
      "----------\n",
      "Epoch 213/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112623, val loss: 0.124084, accuracy: -5.92, time: 1612622969.5386 min\n",
      "----------\n",
      "Epoch 214/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112672, val loss: 0.125240, accuracy: -5.89, time: 1612623072.1524 min\n",
      "----------\n",
      "Epoch 215/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112618, val loss: 0.124689, accuracy: -5.90, time: 1612623174.8593 min\n",
      "----------\n",
      "Epoch 216/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112570, val loss: 0.127205, accuracy: -5.79, time: 1612623277.4515 min\n",
      "----------\n",
      "Epoch 217/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112528, val loss: 0.125714, accuracy: -5.86, time: 1612623380.0242 min\n",
      "----------\n",
      "Epoch 218/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112658, val loss: 0.129801, accuracy: -5.69, time: 1612623482.6619 min\n",
      "----------\n",
      "Epoch 219/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112583, val loss: 0.123981, accuracy: -5.93, time: 1612623585.2901 min\n",
      "----------\n",
      "Epoch 220/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112663, val loss: 0.125389, accuracy: -5.88, time: 1612623687.8595 min\n",
      "----------\n",
      "Epoch 221/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112562, val loss: 0.124488, accuracy: -5.91, time: 1612623790.4447 min\n",
      "----------\n",
      "Epoch 222/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112553, val loss: 0.126288, accuracy: -5.85, time: 1612623893.0388 min\n",
      "----------\n",
      "Epoch 223/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112583, val loss: 0.125259, accuracy: -5.86, time: 1612623995.6000 min\n",
      "----------\n",
      "Epoch 224/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112556, val loss: 0.128426, accuracy: -5.77, time: 1612624098.1822 min\n",
      "----------\n",
      "Epoch 225/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112665, val loss: 0.129254, accuracy: -5.71, time: 1612624200.7629 min\n",
      "----------\n",
      "Epoch 226/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112523, val loss: 0.124319, accuracy: -5.92, time: 1612624303.3305 min\n",
      "----------\n",
      "Epoch 227/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112546, val loss: 0.126461, accuracy: -5.83, time: 1612624405.9409 min\n",
      "----------\n",
      "Epoch 228/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112481, val loss: 0.134205, accuracy: -5.58, time: 1612624508.5228 min\n",
      "----------\n",
      "Epoch 229/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112557, val loss: 0.126409, accuracy: -5.84, time: 1612624611.1502 min\n",
      "----------\n",
      "Epoch 230/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112369, val loss: 0.126041, accuracy: -5.86, time: 1612624713.6838 min\n",
      "----------\n",
      "Epoch 231/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112443, val loss: 0.125839, accuracy: -5.87, time: 1612624816.3146 min\n",
      "----------\n",
      "Epoch 232/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112519, val loss: 0.126708, accuracy: -5.82, time: 1612624918.8960 min\n",
      "----------\n",
      "Epoch 233/299\n",
      "Get best val_loss\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112393, val loss: 0.123881, accuracy: -5.93, time: 1612625021.4631 min\n",
      "----------\n",
      "Epoch 234/299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR is 0 dB, 0 th iteration, train loss: 0.112405, val loss: 0.125659, accuracy: -5.86, time: 1612625124.0025 min\n",
      "----------\n",
      "Epoch 235/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112392, val loss: 0.128563, accuracy: -5.77, time: 1612625226.5317 min\n",
      "----------\n",
      "Epoch 236/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112350, val loss: 0.124504, accuracy: -5.92, time: 1612625329.0605 min\n",
      "----------\n",
      "Epoch 237/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112377, val loss: 0.125335, accuracy: -5.89, time: 1612625431.6570 min\n",
      "----------\n",
      "Epoch 238/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112392, val loss: 0.124872, accuracy: -5.90, time: 1612625534.2570 min\n",
      "----------\n",
      "Epoch 239/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112419, val loss: 0.125075, accuracy: -5.90, time: 1612625636.8237 min\n",
      "----------\n",
      "Epoch 240/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112387, val loss: 0.128038, accuracy: -5.78, time: 1612625739.3539 min\n",
      "----------\n",
      "Epoch 241/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112370, val loss: 0.126948, accuracy: -5.82, time: 1612625841.9888 min\n",
      "----------\n",
      "Epoch 242/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112367, val loss: 0.124048, accuracy: -5.92, time: 1612625944.5840 min\n",
      "----------\n",
      "Epoch 243/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112298, val loss: 0.124095, accuracy: -5.93, time: 1612626047.1850 min\n",
      "----------\n",
      "Epoch 244/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112307, val loss: 0.127265, accuracy: -5.82, time: 1612626149.7609 min\n",
      "----------\n",
      "Epoch 245/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112300, val loss: 0.124941, accuracy: -5.89, time: 1612626252.3462 min\n",
      "----------\n",
      "Epoch 246/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112264, val loss: 0.126385, accuracy: -5.85, time: 1612626354.9542 min\n",
      "----------\n",
      "Epoch 247/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112311, val loss: 0.131538, accuracy: -5.63, time: 1612626457.4936 min\n",
      "----------\n",
      "Epoch 248/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112321, val loss: 0.125598, accuracy: -5.86, time: 1612626560.1552 min\n",
      "----------\n",
      "Epoch 249/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112290, val loss: 0.125617, accuracy: -5.88, time: 1612626662.7308 min\n",
      "----------\n",
      "Epoch 250/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112316, val loss: 0.126612, accuracy: -5.85, time: 1612626765.1975 min\n",
      "----------\n",
      "Epoch 251/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112227, val loss: 0.127289, accuracy: -5.79, time: 1612626867.7565 min\n",
      "----------\n",
      "Epoch 252/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112326, val loss: 0.124785, accuracy: -5.90, time: 1612626970.2948 min\n",
      "----------\n",
      "Epoch 253/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112260, val loss: 0.124239, accuracy: -5.92, time: 1612627072.8423 min\n",
      "----------\n",
      "Epoch 254/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112284, val loss: 0.124768, accuracy: -5.91, time: 1612627175.4125 min\n",
      "----------\n",
      "Epoch 255/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112310, val loss: 0.125168, accuracy: -5.90, time: 1612627277.9454 min\n",
      "----------\n",
      "Epoch 256/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112224, val loss: 0.124696, accuracy: -5.91, time: 1612627381.9969 min\n",
      "----------\n",
      "Epoch 257/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112346, val loss: 0.125619, accuracy: -5.88, time: 1612627486.4590 min\n",
      "----------\n",
      "Epoch 258/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112165, val loss: 0.125245, accuracy: -5.89, time: 1612627590.4431 min\n",
      "----------\n",
      "Epoch 259/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112177, val loss: 0.127741, accuracy: -5.80, time: 1612627693.3779 min\n",
      "----------\n",
      "Epoch 260/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112266, val loss: 0.125506, accuracy: -5.88, time: 1612627796.3719 min\n",
      "----------\n",
      "Epoch 261/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112172, val loss: 0.129831, accuracy: -5.70, time: 1612627899.8798 min\n",
      "----------\n",
      "Epoch 262/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112248, val loss: 0.126175, accuracy: -5.86, time: 1612628004.6243 min\n",
      "----------\n",
      "Epoch 263/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112209, val loss: 0.126714, accuracy: -5.82, time: 1612628110.4640 min\n",
      "----------\n",
      "Epoch 264/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112118, val loss: 0.125084, accuracy: -5.89, time: 1612628221.9753 min\n",
      "----------\n",
      "Epoch 265/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112204, val loss: 0.125924, accuracy: -5.87, time: 1612628333.1986 min\n",
      "----------\n",
      "Epoch 266/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112136, val loss: 0.124871, accuracy: -5.91, time: 1612628444.0392 min\n",
      "----------\n",
      "Epoch 267/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112160, val loss: 0.124424, accuracy: -5.92, time: 1612628554.7793 min\n",
      "----------\n",
      "Epoch 268/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112205, val loss: 0.126314, accuracy: -5.85, time: 1612628665.3290 min\n",
      "----------\n",
      "Epoch 269/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112129, val loss: 0.126390, accuracy: -5.86, time: 1612628777.2708 min\n",
      "----------\n",
      "Epoch 270/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112158, val loss: 0.126374, accuracy: -5.83, time: 1612628890.3376 min\n",
      "----------\n",
      "Epoch 271/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112162, val loss: 0.126082, accuracy: -5.86, time: 1612629004.3562 min\n",
      "----------\n",
      "Epoch 272/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112114, val loss: 0.125146, accuracy: -5.89, time: 1612629117.5516 min\n",
      "----------\n",
      "Epoch 273/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112181, val loss: 0.125542, accuracy: -5.86, time: 1612629230.7099 min\n",
      "----------\n",
      "Epoch 274/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112086, val loss: 0.125116, accuracy: -5.90, time: 1612629344.1182 min\n",
      "----------\n",
      "Epoch 275/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112088, val loss: 0.126894, accuracy: -5.82, time: 1612629456.1296 min\n",
      "----------\n",
      "Epoch 276/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112016, val loss: 0.129400, accuracy: -5.71, time: 1612629567.1637 min\n",
      "----------\n",
      "Epoch 277/299\n",
      "SNR is 0 dB, 0 th iteration, train loss: 0.112147, val loss: 0.125823, accuracy: -5.88, time: 1612629678.4909 min\n",
      "----------\n",
      "Epoch 278/299\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-af1139cae25c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         }\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mtrain_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-716927e94a55>\u001b[0m in \u001b[0;36mtrain_val\u001b[1;34m(model, params)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanity_check\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             \u001b[0mloss_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mmetric_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_metric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-716927e94a55>\u001b[0m in \u001b[0;36mloss_epoch\u001b[1;34m(model, loss_func, dataset_dl, sanity_check, opt)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mxb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mxb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mloss_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mloss_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-ee7e0c7667f6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for snr in SNR:\n",
    "    for iters in range(1):        \n",
    "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model=channel_estimation().to(device) # model initialization  \n",
    "        loss_func = nn.MSELoss() # loss function \n",
    "        opt = optim.Adam(model.parameters(), lr=0.001) # Adam optimizer\n",
    "        params_train={\n",
    "            'num_epochs':300,\n",
    "            'optimizer': opt,\n",
    "            'loss_func': loss_func,\n",
    "            'train_dl': train_dl,\n",
    "            'val_dl': val_dl,\n",
    "            'sanity_check': False,\n",
    "            'path2weights': './models/weights.pt',\n",
    "        }\n",
    "\n",
    "        train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c9d2aa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\models_torch\\\\0.5_5.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7d5a086a5fcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchannel_estimation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# model initialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34mf'.\\\\models_torch\\\\{cr}_{snr}.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtest_dl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\models_torch\\\\0.5_5.pt'"
     ]
    }
   ],
   "source": [
    "loss_history={'test_0': [], 'test_5': [], 'test_10': [], 'test_20': []}\n",
    "metric_history={'test_0': [], 'test_5': [], 'test_10': [], 'test_20': []}\n",
    "sanity_check=False\n",
    "\n",
    "SNR=[5]\n",
    "for snr in SNR:\n",
    "    for iters in range(1):   \n",
    "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model=channel_estimation().to(device) # model initialization  \n",
    "        model.load_state_dict(torch.load( f'.\\\\models_torch\\\\{cr}_{snr}.pt'))\n",
    "        model.eval()\n",
    "        test_dl=data.DataLoader(x_test, batch_size=128, shuffle=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_loss, test_metric=loss_epoch(model, loss_func, test_dl, sanity_check)\n",
    "            loss_history[f'test_{snr}'].append(test_loss)\n",
    "            metric_history[f'test_{snr}'].append(test_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece05fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_0': [-6.098152090307767],\n",
       " 'test_10': [-12.26807310797302],\n",
       " 'test_20': [-15.1880841676938]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe49f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
